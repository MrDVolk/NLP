{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitry.Volkov\\Anaconda3\\envs\\support-cases\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "100%|██████████| 12230/12230 [00:02<00:00, 5135.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.text_preprocessing import preprocess_text, tokenize\n",
    "from src.utils.reporting import get_cross_validation_report\n",
    "from src.utils.vector_space_analysis import *\n",
    "from src.utils.common import *\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv('data/reviews_excerpt.csv')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    df['text_pp'] = df['text'].progress_apply(lambda row: preprocess_text(row, removing_stopwords=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import torch\n",
    "\n",
    "\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, bert_tokenizer, bert_model, *, max_length=60, embedding_func=None):\n",
    "        self.tokenizer = bert_tokenizer\n",
    "        self.model = bert_model\n",
    "        self.model.eval()\n",
    "        self.max_length = max_length\n",
    "        self.embedding_func = embedding_func\n",
    "\n",
    "        if self.embedding_func is None:\n",
    "            self.embedding_func = lambda x: x[0][:, 0, :].squeeze()\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        tokenized_data = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=self.max_length\n",
    "        )['input_ids']\n",
    "\n",
    "        # Create an attention mask telling BERT to use all words\n",
    "        attention_mask = [1] * len(tokenized_data)\n",
    "        return (\n",
    "            torch.tensor(tokenized_data).unsqueeze(0),\n",
    "            torch.tensor(attention_mask).unsqueeze(0),\n",
    "        )\n",
    "\n",
    "    def _tokenize_and_predict(self, text):\n",
    "        tokenized, attention_mask = self._tokenize(text)\n",
    "        embeddings = self.model(tokenized, attention_mask)\n",
    "        return self.embedding_func(embeddings)\n",
    "\n",
    "    def transform(self, text_entries):\n",
    "        if isinstance(text_entries, pd.Series):\n",
    "            text_entries = text_entries.tolist()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            return torch.stack([self._tokenize_and_predict(text) for text in text_entries])\n",
    "\n",
    "    def fit(self, entries, labels=None):\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:18<05:13, 78.41s/it]"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "max_length = 140\n",
    "\n",
    "cc = df['text'].apply(lambda row: len(row))\n",
    "sample_df = df[cc <= max_length].copy().reset_index(drop=True)\n",
    "\n",
    "X, y = sample_df['text_pp'], sample_df['score'].to_numpy()\n",
    "\n",
    "weighted_f1, report_df, confusion_df = get_cross_validation_report(\n",
    "    X, y,\n",
    "    model_factory=lambda: Pipeline([\n",
    "        ('bert', BertTransformer(tokenizer, bert_model, max_length=max_length)),\n",
    "        ('smote', SMOTE()),\n",
    "        ('svc', SVC()),\n",
    "    ]),\n",
    "    seed=0\n",
    ")\n",
    "print(weighted_f1)\n",
    "display(report_df)\n",
    "display(confusion_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:54<00:00, 94.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "     precision    recall        f1  support\n1.0   0.551613  0.566225  0.558824    302.0\n2.0   0.373585  0.397590  0.385214    249.0\n3.0   0.348148  0.408696  0.376000    230.0\n4.0   0.379167  0.305369  0.338290    298.0\n5.0   0.618182  0.608696  0.613402    391.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.0</th>\n      <td>0.551613</td>\n      <td>0.566225</td>\n      <td>0.558824</td>\n      <td>302.0</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>0.373585</td>\n      <td>0.397590</td>\n      <td>0.385214</td>\n      <td>249.0</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.348148</td>\n      <td>0.408696</td>\n      <td>0.376000</td>\n      <td>230.0</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>0.379167</td>\n      <td>0.305369</td>\n      <td>0.338290</td>\n      <td>298.0</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.618182</td>\n      <td>0.608696</td>\n      <td>0.613402</td>\n      <td>391.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "          Pred 1.0  Pred 2.0  Pred 3.0  Pred 4.0  Pred 5.0\nTrue 1.0       171        68        37        10        16\nTrue 2.0        54        99        66        18        12\nTrue 3.0        37        55        94        31        13\nTrue 4.0        18        28        55        91       106\nTrue 5.0        30        15        18        90       238",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pred 1.0</th>\n      <th>Pred 2.0</th>\n      <th>Pred 3.0</th>\n      <th>Pred 4.0</th>\n      <th>Pred 5.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True 1.0</th>\n      <td>171</td>\n      <td>68</td>\n      <td>37</td>\n      <td>10</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>True 2.0</th>\n      <td>54</td>\n      <td>99</td>\n      <td>66</td>\n      <td>18</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>True 3.0</th>\n      <td>37</td>\n      <td>55</td>\n      <td>94</td>\n      <td>31</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>True 4.0</th>\n      <td>18</td>\n      <td>28</td>\n      <td>55</td>\n      <td>91</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>True 5.0</th>\n      <td>30</td>\n      <td>15</td>\n      <td>18</td>\n      <td>90</td>\n      <td>238</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from IPython.display import display\n",
    "\n",
    "max_length = 140\n",
    "\n",
    "cc = df['text'].apply(lambda row: len(row))\n",
    "sample_df = df[cc <= max_length].copy().reset_index(drop=True)\n",
    "\n",
    "X, y = sample_df['text_pp'], sample_df['score'].to_numpy()\n",
    "\n",
    "weighted_f1, report_df, confusion_df = get_cross_validation_report(\n",
    "    X, y,\n",
    "    model_factory=lambda: Pipeline([\n",
    "        ('transform', FeatureUnion([\n",
    "            ('bert', BertTransformer(tokenizer, bert_model, max_length=max_length)),\n",
    "            ('tfidf', TfidfVectorizer(ngram_range=(1, 1), tokenizer=lambda row: tokenize(row, stem=True))),\n",
    "        ])),\n",
    "        ('smote', SMOTE()),\n",
    "        ('svc', SVC()),\n",
    "    ]),\n",
    "    seed=0\n",
    ")\n",
    "print(weighted_f1)\n",
    "display(report_df)\n",
    "display(confusion_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}