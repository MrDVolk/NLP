{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dmitry.Volkov\\Anaconda3\\envs\\support-cases-2\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "100%|██████████| 12230/12230 [00:03<00:00, 3739.61it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.text_preprocessing import preprocess_text, tokenize\n",
    "from src.utils.reporting import get_cross_validation_report\n",
    "from src.utils.vector_space_analysis import *\n",
    "from src.utils.common import *\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv('data/reviews_excerpt.csv')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    df['text_pp'] = df['text'].progress_apply(lambda row: preprocess_text(row, removing_stopwords=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "document_rnn_embeddings = DocumentRNNEmbeddings([glove_embedding])\n",
    "\n",
    "def rnn_vectorization(input_array):\n",
    "    sentences = [Sentence(text) for text in input_array]\n",
    "    for sentence in sentences:\n",
    "        document_rnn_embeddings.embed(sentence)\n",
    "    return np.array([sentence.get_embedding().detach().numpy() for sentence in sentences])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [22:06<00:00, 265.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "     precision    recall        f1  support\n1.0   0.335985  0.362633  0.348801   2446.0\n2.0   0.268890  0.260425  0.264590   2446.0\n3.0   0.254223  0.246116  0.250104   2446.0\n4.0   0.252166  0.226083  0.238413   2446.0\n5.0   0.328195  0.356909  0.341951   2446.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.0</th>\n      <td>0.335985</td>\n      <td>0.362633</td>\n      <td>0.348801</td>\n      <td>2446.0</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>0.268890</td>\n      <td>0.260425</td>\n      <td>0.264590</td>\n      <td>2446.0</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>0.254223</td>\n      <td>0.246116</td>\n      <td>0.250104</td>\n      <td>2446.0</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>0.252166</td>\n      <td>0.226083</td>\n      <td>0.238413</td>\n      <td>2446.0</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>0.328195</td>\n      <td>0.356909</td>\n      <td>0.341951</td>\n      <td>2446.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "          Pred 1.0  Pred 2.0  Pred 3.0  Pred 4.0  Pred 5.0\nTrue 1.0       887       531       392       303       333\nTrue 2.0       582       637       489       378       360\nTrue 3.0       453       458       602       482       451\nTrue 4.0       351       399       500       553       643\nTrue 5.0       367       344       385       477       873",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pred 1.0</th>\n      <th>Pred 2.0</th>\n      <th>Pred 3.0</th>\n      <th>Pred 4.0</th>\n      <th>Pred 5.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>True 1.0</th>\n      <td>887</td>\n      <td>531</td>\n      <td>392</td>\n      <td>303</td>\n      <td>333</td>\n    </tr>\n    <tr>\n      <th>True 2.0</th>\n      <td>582</td>\n      <td>637</td>\n      <td>489</td>\n      <td>378</td>\n      <td>360</td>\n    </tr>\n    <tr>\n      <th>True 3.0</th>\n      <td>453</td>\n      <td>458</td>\n      <td>602</td>\n      <td>482</td>\n      <td>451</td>\n    </tr>\n    <tr>\n      <th>True 4.0</th>\n      <td>351</td>\n      <td>399</td>\n      <td>500</td>\n      <td>553</td>\n      <td>643</td>\n    </tr>\n    <tr>\n      <th>True 5.0</th>\n      <td>367</td>\n      <td>344</td>\n      <td>385</td>\n      <td>477</td>\n      <td>873</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from IPython.display import display\n",
    "\n",
    "X, y = df['text_pp'], df['score'].to_numpy()\n",
    "\n",
    "weighted_f1, report_df, confusion_df = get_cross_validation_report(\n",
    "    X, y,\n",
    "    model_factory=lambda: Pipeline([\n",
    "        ('embd', FunctionTransformer(func=rnn_vectorization)),\n",
    "        ('smote', SMOTE(random_state=0)),\n",
    "        ('svc', SVC()),\n",
    "    ]),\n",
    "    seed=0\n",
    ")\n",
    "print(weighted_f1)\n",
    "display(report_df)\n",
    "display(confusion_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "487de5025d024ccaa7a873a0fb95af79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading vocab.json:   0%|          | 0.00/878k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68d080b3635a4a9f8c37bd977182a571"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading merges.txt:   0%|          | 0.00/446k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95c8d31f75de4290ad48bff1c1a83f54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/1.29M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6064928894054d858a800ffa95d74fd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54941a6552854943b2c7e5362c670e31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "\n",
    "roberta_document_embeddings = TransformerDocumentEmbeddings('roberta-base')\n",
    "\n",
    "def roberta_transformer_vectorization(input_array):\n",
    "    sentences = [Sentence(text) for text in input_array]\n",
    "    for sentence in sentences:\n",
    "        roberta_document_embeddings.embed(sentence)\n",
    "    return np.array([sentence.get_embedding().detach().numpy() for sentence in sentences])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [41:41<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from IPython.display import display\n",
    "\n",
    "X, y = df['text_pp'], df['score'].to_numpy()\n",
    "\n",
    "weighted_f1, report_df, confusion_df = get_cross_validation_report(\n",
    "    X, y,\n",
    "    model_factory=lambda: Pipeline([\n",
    "        ('embd', FunctionTransformer(func=roberta_transformer_vectorization)),\n",
    "        ('smote', SMOTE(random_state=0)),\n",
    "        ('svc', SVC()),\n",
    "    ]),\n",
    "    seed=0\n",
    ")\n",
    "print(weighted_f1)\n",
    "display(report_df)\n",
    "display(confusion_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}